# -*- coding: utf-8 -*-
"""CV Lab Record 19911A3518

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AlLuoj3CMMmMUCnHFINbE13Ei-SBnwUo

# Week 1 & 2

## OpenCV Installation Command:

> **pip install opencv-python**

## Importing an Image
"""

import cv2 
from google.colab.patches import cv2_imshow
img = cv2.imread("Lena.png")
cv2_imshow(img)

"""## Converting image into RGB"""

import cv2 
import matplotlib.pyplot as plt
img = cv2.imread("Lena.png")
cv2_imshow(img)

image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
cv2_imshow(img)

"""## Converting image into GRAY"""

import cv2 
import matplotlib.pyplot as plt
img = cv2.imread("Lena.png")
print("BGR")
cv2_imshow(img)

print("GRAY")
image_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
cv2_imshow(image_gray)

"""## Plot the three channels of the image"""

import numpy as np
img = cv2.imread("Lena.png", cv2.IMREAD_UNCHANGED)

"""### Blue Channel"""

blue_channel = img[:,:,0]
blue_img = np.zeros(img.shape)
blue_img[:,:,0] = blue_channel
cv2_imshow(blue_img)

"""### Green Channel"""

green_channel = img[:,:,1]
green_img = np.zeros(img.shape)
green_img[:,:,1] = green_channel
cv2_imshow(green_img)

"""### Red Channel"""

red_channel = img[:,:,2]
red_img = np.zeros(img.shape)
red_img[:,:,2] = red_channel
cv2_imshow(red_img)

"""## Transform the image into HLS"""

img = cv2.imread("Lena.png")
img_hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)
cv2_imshow(img_hls)

"""## Transform the image into HSV"""

img = cv2.imread("Lena.png")
img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
cv2_imshow(img_hsv)

"""## Drawing rectangle, lines, circle on Image"""

img = np.zeros((500,500,3), dtype="uint8")
# Changing the color of the image
img[:] = (255,255,255)
# Drawing a black line
cv2.line(img, (0,0), (500,500), (0,0,0), (10))
# Drawing a blue line
cv2.line(img, (0,500), (500,0), (255,0,0), (20))
# Drawing a red line
cv2.line(img, (0,250), (250,0), (0,0,255), (5))
# Drawing a green line
cv2.line(img, (500,250), (0,250), (0,255,0), (30))
# Drawing a yellow line
cv2.line(img, (500,250), (250,500), (0,200,200), (10))
# Drawing a violet line
cv2.line(img, (250,0), (500,250), (200,50,100), (10))
# Drawing a cyan line
cv2.line(img, (0,250), (250,500), (255,255,0), (15))
# Drawing a orange line
cv2.line(img, (250,0), (250,500), (0,100,255), (10))

plt.imshow(img)

cv2.circle(img, (250,250), 150, (0,0,255), (-1))
# Drawing a blue circle
cv2.circle(img, (70,70), 50, (255,0,0), (5))
# Drawing a green circle
cv2.circle(img, (430,430), 50, (0,255,0), (10))
plt.imshow(img)

img = np.zeros((500,500,3),dtype='uint8')
image = cv2.rectangle(img, (25,25), (400,400), (0,255,0), 7)
plt.imshow(image)

"""## Adding Text on Image"""

image = np.zeros((200,500))
font = cv2.FONT_HERSHEY_SIMPLEX
org = (50, 50)
fontScale = 1
color = (255, 0, 0)
thickness = 2
image = cv2.putText(image, 'Computer Vision Lab', org, font, 
                   fontScale, (255,0,0), thickness, cv2.LINE_AA)
cv2_imshow(image)

"""# Week 3 & 4

## Storing and Accessing many Images using Python (pickle)
"""

from PIL import Image
import pickle
img = Image.open('Lena.png')
with open('savedimage.pkl', 'wb') as f:
    pickle.dump(img, f)

"""# Week 5 & 6

## Image Segmentation Using Color Spaces in OpenCV + Python

### Color Spaces and Reading Images in OpenCV
"""

img = cv2.imread("cmyk_paint.png", cv2.IMREAD_UNCHANGED)
cv2_imshow(img)

img = cv2.imread("cmyk_paint.png", cv2.IMREAD_UNCHANGED)
blue_channel = img[:,:,0]
blue_img = np.zeros(img.shape)
blue_img[:,:,0] = blue_channel
print("Blue Color Space")
cv2_imshow(blue_img)

img = cv2.imread("cmyk_paint.png", cv2.IMREAD_UNCHANGED)
green_channel = img[:,:,1]
green_img = np.zeros(img.shape)
green_img[:,:,1] = green_channel
print("Green Color Space")
cv2_imshow(green_img)

img = cv2.imread("cmyk_paint.png", cv2.IMREAD_UNCHANGED)
red_channel = img[:,:,2]
red_img = np.zeros(img.shape)
red_img[:,:,2] = red_channel
print("Red Color Space")
cv2_imshow(red_img)

"""## Visualizing Nemo in RGB Color Space"""

nemo_img = cv2.imread("nemo5.jpg")
cv2_imshow(nemo_img)

print("Visualizing Nemo in RGB Color Space")
nemo_rgb = cv2.cvtColor(nemo_img, cv2.COLOR_BGR2RGB)
cv2_imshow(nemo_rgb)

"""## Visualizing Nemo in HSV Color Space"""

print("Visualizing Nemo in HSV Color Space")
nemo_hsv = cv2.cvtColor(nemo_img, cv2.COLOR_BGR2HSV)
cv2_imshow(nemo_hsv)

from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
from matplotlib import colors

r, g, b = cv2.split(nemo_img)
fig = plt.figure()
axis = fig.add_subplot(1, 1, 1, projection="3d")
pixel_colors = nemo_img.reshape((np.shape(nemo_img)[0]*np.shape(nemo_img)[1], 
                                 3))
norm = colors.Normalize(vmin=-1.,vmax=1.)
norm.autoscale(pixel_colors)
pixel_colors = norm(pixel_colors).tolist()
axis.scatter(r.flatten(), g.flatten(), b.flatten(), 
             facecolors=pixel_colors, marker=".")
axis.set_xlabel("Red")
axis.set_ylabel("Green")
axis.set_zlabel("Blue")
plt.show()

"""# Week 7 & 8

## Face Detection in Python, OpenCV
"""

face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
img = cv2.imread("Lena.png")
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
faces = face_cascade.detectMultiScale(gray, 1.3, 5)

for (x,y,w,h) in faces:
    cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2) 
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = img[y:y+h, x:x+w]
  
cv2_imshow(img)

"""## Face Detection in Python, OpenCV - Using a Webcam"""

import cv2
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
cap = cv2.VideoCapture(0)

while 1:
	ret, img = cap.read()

	gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
	faces = face_cascade.detectMultiScale(gray, 1.3, 5)

	for (x,y,w,h) in faces:
		cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)
		roi_gray = gray[y:y+h, x:x+w]
		roi_color = img[y:y+h, x:x+w]
	cv2.imshow('img',img)

	k = cv2.waitKey(30) & 0xff
	if k == 27:
		break
cap.release()
cv2.destroyAllWindows()

"""# Week 9 & 10

## Handling Images with Tensorflow over CoLab

## Loading Data Set (Brain Tumor Dataset)
"""

import keras
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import cv2
import tensorflow as tf

training_datagen = ImageDataGenerator()

training_data_path = "/content/drive/MyDrive/Data Sets/Brain Tumor Dataset/Data"

training_data = training_datagen.flow_from_directory(
    training_data_path,
    target_size=(224, 224), class_mode='binary'
    )

plot_image = plt.figure(figsize=(10,10))

plot1 = plot_image.add_subplot(2,2,1)
plot2 = plot_image.add_subplot(2,2,2)
plot3 = plot_image.add_subplot(2,2,3)
plot4 = plot_image.add_subplot(2,2,4)

plot1.matshow(plt.imread(training_data.filepaths[20]))
plot2.matshow(plt.imread(training_data.filepaths[128]))
plot3.matshow(plt.imread(training_data.filepaths[287]))
plot4.matshow(plt.imread(training_data.filepaths[189]))

"""# CNN Model"""

model = keras.models.Sequential([
          #CNN layers
          keras.layers.Conv2D(filters=32, kernel_size=3,activation='relu', 
                              input_shape=[224, 224, 3]),
          keras.layers.MaxPooling2D(pool_size=(2,2)),
          keras.layers.Conv2D(filters=64,activation='relu', kernel_size=3),
          keras.layers.MaxPooling2D(pool_size=(2,2)),

          #ANN layers for classification
          keras.layers.Flatten(), 
          keras.layers.Dense(units=64, activation='relu'), 
          keras.layers.Dropout(0.1),                                    
          keras.layers.Dense(units=128, activation='relu'),                                    
          keras.layers.Dropout(0.25),                                    
          keras.layers.Dense(units=1, activation='sigmoid') 
])

model.compile(optimizer = tf.optimizers.Adam(0.0001),
              loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

history = model.fit(training_data, epochs=5)

training_data

"""# ResNet50"""

from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, 
decode_predictions
from tensorflow.keras.optimizers import Adam

resnet50 = ResNet50(
    include_top=True,
    weights="imagenet",
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,)

for layer in resnet50.layers:
  layer.trainable = False

resnet_model = keras.Sequential()
resnet_model.add(resnet50)

resnet_model.add(keras.layers.Dense(units=64,activation="relu"))
resnet_model.add(keras.layers.Dense(units=128,activation="relu"))
resnet_model.add(keras.layers.Dense(units=1,activation="sigmoid"))

resnet_model.summary()

resnet_model.compile(optimizer = Adam(learning_rate = 0.0001),
                     loss='binary_crossentropy', metrics=['accuracy'])

resnet_model.fit(training_data, epochs=1)

resnet_model.fit(training_data, epochs=1)

"""# Mobile Net"""

from tensorflow.keras.applications.mobilenet import MobileNet

mobilenet = MobileNet(
    input_shape=None,
    include_top=True,
    weights="imagenet",
    input_tensor=None,
    pooling=None,
    classes=1000,
)

for layer in mobilenet.layers:
  layer.trainalbe = False

mobilenet_model = keras.Sequential()
mobilenet_model.add(mobilenet)

mobilenet_model.add(keras.layers.Dense(units=64,activation="relu"))
mobilenet_model.add(keras.layers.Dense(units=128,activation="relu"))
mobilenet_model.add(keras.layers.Dense(units=1,activation="sigmoid"))

mobilenet_model.summary()

mobilenet_model.compile(optimizer = Adam(learning_rate = 0.0001),
                        loss='binary_crossentropy', metrics=['accuracy'])

mobilenet_model.fit(training_data, epochs=1)

mobilenet_model.fit(training_data, epochs=1)

"""# VGG16"""

from tensorflow.keras.applications.vgg16 import VGG16

vgg16 = VGG16(
    input_shape=None,
    include_top=True,
    weights="imagenet",
    input_tensor=None,
    pooling=None,
    classes=1000,
)

for layer in vgg16.layers:
  layer.trainalbe = False

vgg16_model = keras.Sequential()
vgg16_model.add(vgg16)

vgg16_model.add(keras.layers.Dense(units=64,activation="relu"))
vgg16_model.add(keras.layers.Dense(units=128,activation="relu"))
vgg16_model.add(keras.layers.Dense(units=1,activation="sigmoid"))

vgg16_model.summary()

vgg16_model.compile(optimizer = Adam(learning_rate = 0.0001),
                    loss='binary_crossentropy', metrics=['accuracy'])

vgg16_model.fit(training_data, epochs=1)

"""## Converting normal Image to cartoon image using OpenCV & Python"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

img = cv2.imread("Lena.png")
img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
plt.figure(figsize=(6,6))
plt.imshow(img)
plt.axis("off")
plt.title("Original Image")
plt.show()

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
gray = cv2.medianBlur(gray, 5)
plt.figure(figsize=(6,6))
plt.imshow(gray,cmap="gray")
plt.axis("off")
plt.title("Grayscale Image")
plt.show()

edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)
plt.figure(figsize=(6,6))
plt.imshow(edges,cmap="gray")
plt.axis("off")
plt.title("Edged Image")
plt.show()

color = cv2.bilateralFilter(img, 9, 250, 250)
cartoon = cv2.bitwise_and(color, color, mask=edges)
plt.figure(figsize=(6,16))
plt.imshow(cartoon,cmap="gray")
plt.axis("off")
plt.title("Cartoon Image")
plt.show()

"""## Line detection in python with OpenCV | Hough line method"""

import cv2
import numpy as np
img = cv2.imread("window.jpg")
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
edges = cv2.Canny(gray, 75, 150)
lines = cv2.HoughLinesP(edges, 1, np.pi/180, 30, maxLineGap=250)
for line in lines:
   x1, y1, x2, y2 = line[0]
   cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 1)
cv2_imshow(edges)
cv2_imshow(img)





########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################



model = Sequential()

# 1st Convolutional Layer
model.add(Conv2D(filters = 96, input_shape = (224, 224, 3),
			kernel_size = (11, 11), strides = (4, 4),
			padding = 'valid'))
model.add(Activation('relu'))
# Max-Pooling
model.add(MaxPooling2D(pool_size = (2, 2),
			strides = (2, 2), padding = 'valid'))
# Batch Normalisation
model.add(BatchNormalization())

# 2nd Convolutional Layer
model.add(Conv2D(filters = 256, kernel_size = (11, 11),
			strides = (1, 1), padding = 'valid'))
model.add(Activation('relu'))
# Max-Pooling
model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),
			padding = 'valid'))
# Batch Normalisation
model.add(BatchNormalization())

# 3rd Convolutional Layer
model.add(Conv2D(filters = 384, kernel_size = (3, 3),
			strides = (1, 1), padding = 'valid'))
model.add(Activation('relu'))
# Batch Normalisation
model.add(BatchNormalization())

# 4th Convolutional Layer
model.add(Conv2D(filters = 384, kernel_size = (3, 3),
			strides = (1, 1), padding = 'valid'))
model.add(Activation('relu'))
# Batch Normalisation
model.add(BatchNormalization())

# 5th Convolutional Layer
model.add(Conv2D(filters = 256, kernel_size = (3, 3),
			strides = (1, 1), padding = 'valid'))
model.add(Activation('relu'))
# Max-Pooling
model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2),
			padding = 'valid'))
# Batch Normalisation
model.add(BatchNormalization())

# Flattening
model.add(Flatten())

# 1st Dense Layer
model.add(Dense(4096, input_shape = (224*224*3, )))
model.add(Activation('relu'))
# Add Dropout to prevent overfitting
model.add(Dropout(0.4))
# Batch Normalisation
model.add(BatchNormalization())

# 2nd Dense Layer
model.add(Dense(4096))
model.add(Activation('relu'))
# Add Dropout
model.add(Dropout(0.4))
# Batch Normalisation
model.add(BatchNormalization())

# Output Softmax Layer
model.add(Dense(num_classes))
model.add(Activation('softmax'))

#############################################################################################################################
#############################################################################################################################



import keras
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import cv2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from tensorflow.keras.optimizers import Adam
import tensorflow as tf 

training_datagen = ImageDataGenerator(rescale=1./255,
                                      rotation_range=40,
                                      width_shift_range=0.2,
                                      height_shift_range=0.2,
                                      shear_range=0.2,
                                      zoom_range=0.2,
                                      horizontal_flip=True,
                                      fill_mode='nearest')


training_data_path = "/content/drive/MyDrive/4-1 Mini Project/data3"


training_data = training_datagen.flow_from_directory(training_data_path, target_size=(224, 224), class_mode='binary')


plot_image = plt.figure(figsize=(10,10))

plot1 = plot_image.add_subplot(2,2,1)
plot2 = plot_image.add_subplot(2,2,2)
plot3 = plot_image.add_subplot(2,2,3)
plot4 = plot_image.add_subplot(2,2,4)

plot1.matshow(plt.imread(training_data.filepaths[2]))
plot2.matshow(plt.imread(training_data.filepaths[13]))
plot3.matshow(plt.imread(training_data.filepaths[24]))
plot4.matshow(plt.imread(training_data.filepaths[32]))



from tensorflow.keras.applications.mobilenet import MobileNet

mobilenet = MobileNet(
    input_shape=None,
    include_top=True,
    weights="imagenet",
    input_tensor=None,
    pooling=None,
    classes=1000,
)

for layer in mobilenet.layers:
  layer.trainalbe = False


mobilenet_model = keras.Sequential()
mobilenet_model.add(mobilenet)


mobilenet_model.add(keras.layers.Dense(units=64,activation="relu"))
mobilenet_model.add(keras.layers.Dense(units=128,activation="relu"))
mobilenet_model.add(keras.layers.Dense(units=1,activation="sigmoid"))

mobilenet_model.summary()


mobilenet_model.compile(optimizer = Adam(learning_rate = 0.0001), loss='binary_crossentropy', metrics=['accuracy'])


mobilenet_model.fit(training_data, epochs=15)

import matplotlib.pyplot as plt
import numpy as np
import cv2
from keras.models import load_model 
import os



def predict_output(img_path):
    img = cv2.imread(img_path)
    img = cv2.resize(img,(224,224))
    img = img/255
    img = np.expand_dims(img,axis=0)
    prediction = mobilenet_model.predict(img)
    prediction = prediction >= 0.5
    return prediction


predict_output("/content/drive/MyDrive/4-1 Mini Project/data3/Headset/pic11.png")





